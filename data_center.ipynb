{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from config import loading_parameters\n",
    "from processing_data import main as process_data\n",
    "\n",
    "from telethon.tl.functions.messages import GetHistoryRequest\n",
    "from telethon.tl.types import User, PeerUser\n",
    "from telethon.errors import FloodWaitError\n",
    "from telethon import TelegramClient\n",
    "from dotenv import load_dotenv \n",
    "\n",
    "import parsers.telegram.telegram_parse as telegram_parse\n",
    "import parsers.discord.discord_parse as discord_parse\n",
    "import parsers.instagram.instagram_parse as instagram_parse\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import yaml\n",
    "import asyncio\n",
    "import os \n",
    "import re\n",
    "import json \n",
    "import time \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as f:\n",
    "    full_config = yaml.safe_load(f)\n",
    "\n",
    "loading_parameters = full_config.get('loading_parameters', {})\n",
    "\n",
    "ROOT_PATH                = os.path.abspath(os.getcwd())\n",
    "T_LOCAL_JSON_PATH        = os.path.abspath(os.path.join(ROOT_PATH, loading_parameters.get(\"t_local_json_path\")))\n",
    "T_GLOBAL_SAVE_PATH       = os.path.abspath(os.path.join(ROOT_PATH, loading_parameters.get(\"t_global_save_path\")))\n",
    "DISCORD_PACKAGE_FOLDER   = os.path.abspath(os.path.join(ROOT_PATH, loading_parameters.get(\"discord_package_folder\")))\n",
    "INBOX_PATH               = os.path.abspath(os.path.join(ROOT_PATH, loading_parameters.get(\"inbox_path\")))\n",
    "SAVE_PATH                = os.path.abspath(os.path.join(ROOT_PATH, \"Datasets/\"))\n",
    "# TODO: When finished, integrate .env with config.yaml\n",
    "INSTAGRAM_USERNAME       = os.getenv('INSTAGRAM_USERNAME') \n",
    "T_PARSE_TYPE             = loading_parameters.get(\"t_parse_type\")\n",
    "TELEGRAM                 = loading_parameters.get(\"telegram\")\n",
    "INSTAGRAM                = loading_parameters.get(\"instagram\")\n",
    "DISCORD                  = loading_parameters.get(\"discord\")\n",
    "CHECKPOINTS              = loading_parameters.get(\"checkpoints\")\n",
    "SAVE_CSV                 = loading_parameters.get(\"save_csv\")\n",
    "MESSAGE_LIMIT            = loading_parameters.get(\"message_limit\")\n",
    "DIALOGS_LIMIT            = loading_parameters.get(\"dialogs_limit\") \n",
    "VERBOSE                  = loading_parameters.get(\"verbose\") \n",
    "THRESHOLD                = loading_parameters.get(\"threshold\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main(telegram = TELEGRAM,\n",
    "               instagram = INSTAGRAM,\n",
    "               discord = DISCORD,\n",
    "               discord_path = DISCORD_PACKAGE_FOLDER,\n",
    "               **kwargs) -> list: \n",
    "      \"\"\"\n",
    "      Returns: \n",
    "            List: A list with true boolean parsers.\n",
    "      \"\"\"\n",
    "      \n",
    "      to_return = {}\n",
    "      \n",
    "      if telegram:\n",
    "            telegram_df = await telegram_parse.main(parse_type=T_PARSE_TYPE,json_path=T_LOCAL_JSON_PATH, save_path=T_GLOBAL_SAVE_PATH, **kwargs,)\n",
    "            to_return['telegram_dataset'] = telegram_df\n",
    "      if instagram:\n",
    "            instagram_df = instagram_parse.main(inbox_path=INBOX_PATH, instagram_username=INSTAGRAM_USERNAME, **kwargs)\n",
    "            to_return['instagram_dataset'] = instagram_df\n",
    "      if discord:\n",
    "            discord_df = discord_parse.main(path=discord_path, **kwargs)\n",
    "            to_return['discord_dataset'] = discord_df\n",
    "\n",
    "      return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "      \"save_csv\": SAVE_CSV,\n",
    "      \"message_limit\": MESSAGE_LIMIT,\n",
    "      \"dialogs_limit\": DIALOGS_LIMIT,\n",
    "      \"verbose\": VERBOSE,\n",
    "      \"checkpoints\": CHECKPOINTS,\n",
    "      \"threshold\": THRESHOLD\n",
    "}\n",
    "\n",
    "datasets = await main(**kwargs)\n",
    "      \n",
    "# # Iterating over the dictionary key and assigning proper name to it. telegram_dataset = telegram_df\n",
    "# for key, value in datasets.items():\n",
    "#     locals()[key] = value\n",
    "\n",
    "total_messages = sum([len(row_len) for row_len in datasets.values()])\n",
    "print(f\"Collected total of {total_messages} messages\")  \n",
    "\n",
    "# Concatenating dataframes\n",
    "dataset = pd.DataFrame(columns=['Message', 'Sender', 'Date'])\n",
    "for key, value in datasets.items():\n",
    "      dataset = pd.concat([dataset, value])\n",
    "      print(f\"Concatenated {key}\")\n",
    "\n",
    "concatenated_path = os.path.abspath(os.path.join(SAVE_PATH, 'concatenated.csv'))\n",
    "if not os.path.exists(concatenated_path):\n",
    "      print(f\"Saving to {concatenated_path}\")\n",
    "      dataset.to_csv(concatenated_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_path = os.path.join(SAVE_PATH, 'concatenated.csv')\n",
    "dataset = pd.read_csv(concatenated_path)\n",
    "dataset[\"Message\"].to_string\n",
    "dataset.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_date(date): # For graphs \n",
    "      date = pd.to_datetime(date)\n",
    "      return date.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Date'] = dataset['Date'].apply(simplify_date)\n",
    "dataset[\"Date\"].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values? \n",
    "dataset.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by date \n",
    "dataset = dataset.sort_values('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_message_count_over_time(data, bar_width=0.35, font_size=12):\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(10, 5))\n",
    "    # Get messages over years\n",
    "    years_messages = dataset['Date'].dt.year.value_counts()\n",
    "    top_year = years_messages.idxmax()\n",
    "\n",
    "    # Get messages over months in the top year\n",
    "    top_year_data = data[data['Date'].dt.year == top_year]\n",
    "    months_messages = top_year_data['Date'].dt.month.value_counts()\n",
    "    months_messages = months_messages.sort_index(ascending=True)\n",
    "\n",
    "    # Plot the third set of bars -- msg/day in the top months\n",
    "    top_months = top_year_data['Date'].dt.month.value_counts().idxmax()\n",
    "    top_months_data = top_year_data[top_year_data['Date'].dt.month == top_months]\n",
    "    day_messages = top_months_data['Date'].dt.day.value_counts()\n",
    "    day_messages = day_messages.sort_index(ascending=True)\n",
    "\n",
    "    # Plot Years\n",
    "    axs[0].bar(years_messages.index, years_messages.values, color='red')\n",
    "    axs[0].set_title(top_year, fontsize=font_size)\n",
    "    axs[0].set_xlabel(f'Years', fontsize=font_size)\n",
    "    axs[0].set_ylabel('Number of Messages', fontsize=font_size)\n",
    "\n",
    "    # Plot Months \n",
    "    top_months = months_messages.index[-1]\n",
    "    axs[1].bar(months_messages.index, months_messages.values, color='blue')\n",
    "    axs[1].set_title(f\"{top_months}/{top_year}\", fontsize=font_size)\n",
    "    axs[1].set_xlabel(f'Months', fontsize=font_size)\n",
    "    axs[1].set_ylabel('Number of Messages', fontsize=font_size)\n",
    "\n",
    "    # Plot days\n",
    "    last_day = day_messages.index[-1]\n",
    "    axs[2].bar(day_messages.index, day_messages.values, color='g')\n",
    "    axs[2].set_title(f\"{top_months}/1-{last_day}/{last_day}\", fontsize=font_size)\n",
    "    axs[2].set_xlabel(f'Days', fontsize=font_size)\n",
    "    axs[2].set_ylabel('Number of Messages', fontsize=font_size)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(dataset):\n",
    "    # Make a full copy of the dataset, not just the 'Date' column\n",
    "    df = dataset.copy()\n",
    "\n",
    "    # Ensure 'Date' is in datetime format\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "    # Extract Year, Month, and Day from the 'Date' column\n",
    "    df['Year'] = df['Date'].dt.year\n",
    "    df['Month'] = df['Date'].dt.month\n",
    "    df['Day'] = df['Date'].dt.day\n",
    "\n",
    "    # Group by Year, Month, and Day and count occurrences\n",
    "    grouped_data = df.groupby(['Year', 'Month', 'Day']).size().reset_index(name='Message Count')\n",
    "\n",
    "    # Pivot table for heatmap (rows: 'Day', columns: 'Month-Year', values: 'Message Count')\n",
    "    grouped_data['Month-Year'] = grouped_data['Year'].astype(str) + '-' + grouped_data['Month'].astype(str)\n",
    "    heatmap_data = grouped_data.pivot(index='Day', columns='Month-Year', values='Message Count')\n",
    "\n",
    "    # Create heatmap\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(heatmap_data, cmap=\"coolwarm\", cbar_kws={'label': 'Number of Messages'}, linewidths=0.1, linecolor='gray')\n",
    "\n",
    "    plt.title('Messages Amount per Day')\n",
    "    plt.xlabel('Month-Year')\n",
    "    plt.ylabel('Days')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_message_count_over_time(data=dataset), plot_heatmap(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = process_data()\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
