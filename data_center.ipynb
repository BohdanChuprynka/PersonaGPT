{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from telethon.tl.functions.messages import GetHistoryRequest\n",
    "from telethon.tl.types import User, PeerUser\n",
    "from telethon.errors import FloodWaitError\n",
    "from telethon import TelegramClient\n",
    "from dotenv import load_dotenv \n",
    "\n",
    "import parsers.telegram.telegram_parse as telegram_parse\n",
    "import parsers.discord.discord_parse as discord_parse\n",
    "import parsers.instagram.instagram_parse as instagram_parse\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import asyncio\n",
    "import os \n",
    "import re\n",
    "import json \n",
    "import time \n",
    "import openai\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram: bool = True                                 # Whether parse telegram data\n",
    "t_parse_type = \"local\"                                # \"local\" or global\" # Whether parse your messages through JSON Files that located locally (Fast way) or globally: (Via API) (takes 1 hour for ~20k messages) (Fill .env file)\n",
    "json_path = \"/Users/bohdan/Documents/Programming/Projects/VSCode/AI-DataScience/PersonaGPT/parsers/telegram/result.json\" # If t_parse_type is \"local\", then fill it\n",
    "telegram_save_path = r\"/Users/bohdan/Documents/Programming/Projects/VSCode/AI-DataScience/PersonaGPT/parsers/telegram/result.csv\"  # If t_parse_type is \"global\", then fill it\n",
    "# Requires openai for question generation\n",
    "instagram: bool = True                               # Whether parse instagram data\n",
    "inbox_path = \"parsers/instagram/your_instagram_activity/messages/inbox\"  # Path to your instagram inbox\n",
    "instagram_username = os.getenv('INSTAGRAM_USERNAME')                 # Your instagram username\n",
    "# Requires openai for question generation\n",
    "discord: bool = False                                # Whether parse discord data\n",
    "discord_package_folder = \"parsers/discord/package\"    # Root folder that contains all the dialogs (Originally named \"package\")\n",
    "\n",
    "message_limit: int = None                             # The maximum amount of messages to be processed total\n",
    "dialogs_limit: int = None                             # The maximum amount of dialogs to be processed\n",
    "verbose=1                                             # The amount of output to be printed\n",
    "checkpoints: bool = True                              # To save data during parsing\n",
    "threshold: int = 50      \n",
    "save_csv: bool = False                                 # Drop the dialog if it has less or equal messages than the threshold\n",
    "data_save_folder: str = \"Datasets\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_messages(messages):\n",
    "      \"\"\"\n",
    "      Function which uses a set of tuning algorithms to meet the criteria of optimized data for future models.\n",
    "      \"\"\"\n",
    "\n",
    "      # TODO: Include only messages in ukrainian language\n",
    "\n",
    "\n",
    "      # TODO: Put todos below in order of priority \n",
    "      # For each of the points below, if true: add one, if false: minus one\n",
    "      # TODO: Add detection system for context and response:\n",
    "\n",
    "      # TODO: If the message contains question mark in the end of the message, it is a context\n",
    "      # TODO: The first message of the new day is probably a context.\n",
    "      # TODO: If there are few messages in a row from user, concatenate them into one message.\n",
    "      # TODO: If there is a significant time gap (e.g., several hours) between messages, the first message after the gap might be a context.\n",
    "      # TODO: Look for specific keywords or phrases that typically indicate a context (e.g., \"What do you think about...\", \"Can you explain...\", \"Why is...\").\n",
    "      # TODO: If a message is a direct reply to a previous context message, it is likely a response.\n",
    "      # TODO: Short messages that directly follow a context are likely responses.\n",
    "      # TODO: If the same user repeatedly sends messages ending with question marks or messages at the start of the day, those are likely contexts.\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_context(response): # GPT Required \n",
    "      \"\"\"\n",
    "      Uses AI to generate context based on response\n",
    "      \"\"\" \n",
    "      #openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "      prompt = f'Classify the following message as either \"context\" or \"response\":\\n\\n\"{message}\"\\n\\nAnswer with one word only.'\n",
    "      \n",
    "      response = openai.Completion.create(\n",
    "            engine=\"GPT-4\",  # Choose a suitable engine\n",
    "            prompt=prompt,\n",
    "            max_tokens=10,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            temperature=0.5,\n",
    "      )\n",
    "      \n",
    "      return response.choices[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main(telegram = telegram,\n",
    "               instagram = instagram,\n",
    "               discord = discord,\n",
    "               discord_path = discord_package_folder,\n",
    "               **kwargs) -> list: \n",
    "      \"\"\"\n",
    "      Returns: \n",
    "            List: A list with true boolean parsers.\n",
    "      \"\"\"\n",
    "      \n",
    "      to_return = {}\n",
    "      \n",
    "      if telegram:\n",
    "            telegram_df = await telegram_parse.main(parse_type=t_parse_type,json_path=json_path, save_path=telegram_save_path, **kwargs,)\n",
    "            to_return['telegram_dataset'] = telegram_df\n",
    "      if instagram:\n",
    "            instagram_df = instagram_parse.main(inbox_path=inbox_path, instagram_username=instagram_username, **kwargs)\n",
    "            to_return['instagram_dataset'] = instagram_df\n",
    "      if discord:\n",
    "            discord_df = discord_parse.main(path=discord_path, **kwargs)\n",
    "            to_return['discord_dataset'] = discord_df\n",
    "\n",
    "      return to_return\n",
    "\n",
    "      print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "      \"save_csv\": save_csv,\n",
    "      \"message_limit\": message_limit,\n",
    "      \"dialogs_limit\": dialogs_limit,\n",
    "      \"verbose\": verbose,\n",
    "      \"checkpoints\": checkpoints,\n",
    "      \"threshold\": threshold\n",
    "}\n",
    "\n",
    "datasets = await main(**kwargs)\n",
    "      \n",
    "# # Iterating over the dictionary key and assigning proper name to it. telegram_dataset = telegram_df\n",
    "# for key, value in datasets.items():\n",
    "#     locals()[key] = value\n",
    "\n",
    "total_messages = sum([len(row_len) for row_len in datasets.values()])\n",
    "print(f\"Collected total of {total_messages} messages\")  \n",
    "\n",
    "# Concatenating dataframes\n",
    "dataset = pd.DataFrame(columns=['Message', 'Sender', 'Date'])\n",
    "for key, value in datasets.items():\n",
    "      dataset = pd.concat([dataset, value])\n",
    "      print(f\"Concatenated {key}\")\n",
    "\n",
    "concatenated_path = os.path.join(data_save_folder, 'concatenated.csv')\n",
    "if not os.path.exists(concatenated_path):\n",
    "      print(f\"Saving to {concatenated_path}\")\n",
    "      dataset.to_csv(concatenated_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_path = os.path.join(data_save_folder, 'concatenated.csv')\n",
    "dataset = pd.read_csv(concatenated_path)\n",
    "dataset[\"Message\"].to_string\n",
    "dataset.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_date(date): # For graphs \n",
    "      date = pd.to_datetime(date)\n",
    "      return date.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Date'] = dataset['Date'].apply(simplify_date)\n",
    "dataset[\"Date\"].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values? \n",
    "dataset.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by date \n",
    "dataset = dataset.sort_values('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_message_count_over_time(data, period='D'):\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    \n",
    "    # Resample the data by the specified period (e.g., day, week, month)\n",
    "    messages_by_time = data.resample(period, on='Date').size()\n",
    "\n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(messages_by_time.index, messages_by_time.values, color='skyblue')\n",
    "    plt.title(f'Messages Sent Per {period}', fontsize=16)\n",
    "    plt.xlabel(f'Time ({period})', fontsize=12)\n",
    "    plt.ylabel('Number of Messages', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(dataset):\n",
    "    # Make a full copy of the dataset, not just the 'Date' column\n",
    "    df = dataset.copy()\n",
    "\n",
    "    # Ensure 'Date' is in datetime format\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "    # Extract Year, Month, and Day from the 'Date' column\n",
    "    df['Year'] = df['Date'].dt.year\n",
    "    df['Month'] = df['Date'].dt.month\n",
    "    df['Day'] = df['Date'].dt.day\n",
    "\n",
    "    # Group by Year, Month, and Day and count occurrences\n",
    "    grouped_data = df.groupby(['Year', 'Month', 'Day']).size().reset_index(name='Message Count')\n",
    "\n",
    "    # Pivot table for heatmap (rows: 'Day', columns: 'Month-Year', values: 'Message Count')\n",
    "    grouped_data['Month-Year'] = grouped_data['Year'].astype(str) + '-' + grouped_data['Month'].astype(str)\n",
    "    heatmap_data = grouped_data.pivot(index='Day', columns='Month-Year', values='Message Count')\n",
    "\n",
    "    # Create heatmap\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(heatmap_data, cmap=\"coolwarm\", cbar_kws={'label': 'Number of Messages'}, linewidths=0.1, linecolor='gray')\n",
    "\n",
    "    plt.title('Messages Amount per Day')\n",
    "    plt.xlabel('Month-Year')\n",
    "    plt.ylabel('Days')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_message_count_over_time(data=dataset, period='D'), plot_heatmap(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My most messaged day.\n",
    "#dataset[dataset['Date'] == pd.to_datetime('2024-03-27')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def to_lowercase(text):\n",
    "#     return text.lower()\n",
    "def remove_urls(text):\n",
    "      return re.sub(r'http\\S+', 'redacted', text)\n",
    "# def remove_punctuation(text):\n",
    "#     translator = str.maketrans('', '', string.punctuation)\n",
    "#    return text.translate(translator)\n",
    "def remove_english_words(text):\n",
    "    ukrainian_words = re.findall(r'\\b[А-Яа-яЁёІіЇїЄєҐґ’]+\\b', text)\n",
    "    return ' '.join(ukrainian_words)\n",
    "def delete_html_tags(text):\n",
    "    clean_text = re.sub(r'<.*?>', '', text)\n",
    "    return clean_text\n",
    "def remove_mention(text):\n",
    "  mention_regex = r\"@\\w+\"\n",
    "  return re.sub(mention_regex, \"/mention\", text)\n",
    "def redact_email(text): \n",
    "    return re.sub(r'\\S+@\\S+', '/email', text)\n",
    "def remove_password(text): \n",
    "    pass_pattern = r'[A-Za-z0-9@#$%^&+=]{8,}'\n",
    "    text.to_string\n",
    "    return re.sub(pass_pattern, ' ', text)\n",
    "def remove_whitespace(text):\n",
    "    return  \" \".join(text.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_password(dataset['Message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TO BE CONTINUED.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
