{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parses and organizes all the messages in telegram account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from telethon import TelegramClient\n",
    "from telethon.tl.functions.messages import GetHistoryRequest\n",
    "from telethon.tl.types import User, PeerUser\n",
    "from telethon.errors import FloodWaitError\n",
    "import asyncio\n",
    "import time \n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_path = \".env\"\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "api_id = os.getenv('TELEGRAM_API_ID')\n",
    "api_hash = os.getenv('TELEGRAM_HASH_ID')\n",
    "phone_number = os.getenv('PHONE_NUMBER')\n",
    "my_telegram_id = os.getenv('my_telegram_id')\n",
    "session_name = \"telegram_parser\"\n",
    "client = TelegramClient(session_name, api_id, api_hash)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "def categorize_message(message):\n",
    "    prompt = f'Classify the following message as either \"context\" or \"response\":\\n\\n\"{message}\"\\n\\nAnswer with one word only.'\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",  # Choose a suitable engine\n",
    "        prompt=prompt,\n",
    "        max_tokens=1,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_messages(messages):\n",
    "      \"\"\"\n",
    "      Function which uses a set of tuning algorithms to meet the criteria of optimized data for future models.\n",
    "      \"\"\"\n",
    "\n",
    "      # TODO: Include only messages in ukrainian language\n",
    "\n",
    "\n",
    "      # TODO: Put todos below in order of priority \n",
    "      # For each of the points below, if true: add one, if false: minus one\n",
    "      # TODO: Add detection system for context and response:\n",
    "\n",
    "      # TODO: If the message contains question mark in the end of the message, it is a context\n",
    "      # TODO: The first message of the new day is probably a context.\n",
    "      # TODO: If there are few messages in a row from user, concatenate them into one message.\n",
    "      # TODO: If there is a significant time gap (e.g., several hours) between messages, the first message after the gap might be a context.\n",
    "      # TODO: Look for specific keywords or phrases that typically indicate a context (e.g., \"What do you think about...\", \"Can you explain...\", \"Why is...\").\n",
    "      # TODO: If a message is a direct reply to a previous context message, it is likely a response.\n",
    "      # TODO: Short messages that directly follow a context are likely responses.\n",
    "      # TODO: If the same user repeatedly sends messages ending with question marks or messages at the start of the day, those are likely contexts.\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_total_messages(session_name, api_id, api_hash, phone_number, only_personal=True):\n",
    "      \"\"\"\n",
    "      Shows a total amount of messages that your account has. \n",
    "      \"\"\"\n",
    "      total_messages = 0\n",
    "\n",
    "      async with TelegramClient(session_name, api_id, api_hash) as client:\n",
    "            client.start(phone_number)\n",
    "            dialogs = await client.get_dialogs()\n",
    "\n",
    "            if only_personal:\n",
    "                  dialogs = [dialog for dialog in dialogs if isinstance(dialog.entity, User)]\n",
    "                  print(f\"Total dialogs: {len(dialogs)}\")\n",
    "            for dialog in dialogs:\n",
    "                  async for message in client.iter_messages(dialog.entity, limit=None):\n",
    "                        total_messages += 1\n",
    "            print(f\"Total messages: {total_messages}\")\n",
    "            client.disconnect()\n",
    "            return total_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes some time to run\n",
    "#%time\n",
    "#total_messages = await get_total_messages(session_name, api_id, api_hash, phone_number, only_personal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def extract_message_info(messages):\n",
    "      extracted_dialog = []\n",
    "      last_message=None\n",
    "\n",
    "      for message in messages:\n",
    "            try: \n",
    "                  text = message.message.strip() if message.message else \"\"\n",
    "                  sender = message.from_id if message.from_id else (await client.get_entity(message.peer_id)).id\n",
    "                  sender = sender.user_id if isinstance(sender, PeerUser) else sender # Deletes PeerUser classes and keeps only int id\n",
    "\n",
    "                  #sent_by_me = my_telegram_id == sender   \n",
    "                  date = message.date \n",
    "            except FloodWaitError as e:\n",
    "                  print(f\"FloodWaitError: sleeping for {e.seconds} seconds.\")\n",
    "                  await asyncio.sleep(e.seconds)\n",
    "                  continue \n",
    "                  \n",
    "            if text:\n",
    "                  if last_message and sender == last_message[1]:\n",
    "                        last_message[0] = \" \".join([last_message[0], text])\n",
    "                  else:\n",
    "                        if last_message:\n",
    "                              extracted_dialog.append(last_message)\n",
    "                        last_message = [text, sender, date]\n",
    "\n",
    "      if last_message:\n",
    "            extracted_dialog.append(last_message)\n",
    "      \n",
    "      return extracted_dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "async def parse_data(threshold: int =50, \n",
    "                     message_limit=None,\n",
    "                      dialogs_limit: int = 100,\n",
    "                      verbose=1,\n",
    "                      top_chats_first: bool = False):\n",
    "    \"\"\"\n",
    "    Parses all the messages in the profile.\n",
    "    \n",
    "    Args:\n",
    "        threshold: int\n",
    "            The minimum amount of messages in a dialog to be processed.\n",
    "        message_limit: int\n",
    "            The maximum amount of messages to be processed in a dialog.\n",
    "        dialogs_limit: int\n",
    "            The maximum amount of dialogs to be processed.\n",
    "        verbose: int\n",
    "            The amount of output to be printed.\n",
    "        top_chats_first: bool\n",
    "            Whether to process chats with most messages first.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame\n",
    "            The parsed data.\n",
    "    \"\"\"\n",
    "    async with client:\n",
    "        # TODO: Implement checkpoint system\n",
    "            # Don't forget about assigning filtered_dialogs\n",
    "            # You can implement in this structure: filtered_dialogs, itered_dialogs.\n",
    "\n",
    "\n",
    "        dialogs = await client.get_dialogs()\n",
    "        dialogs = [dialog for dialog in dialogs if isinstance(dialog.entity, User)]\n",
    "        dialogs = [dialog for dialog in dialogs if not dialog.entity.bot]\n",
    "        dialogs = dialogs[:dialogs_limit]\n",
    "        if verbose: \n",
    "            total = 0 \n",
    "            print(f\"Total dialogs: {len(dialogs)}\")\n",
    "        filtered_dialogs = pd.DataFrame(columns=[\"Message\", \"Sender\",\"Date\"])\n",
    "        for dialog in dialogs[:dialogs_limit]:\n",
    "            start_time = time.time() if verbose else None\n",
    "            messages_info = []\n",
    "            async for message in client.iter_messages(dialog.entity, limit=message_limit, wait_time=10):\n",
    "                messages_info.append(message)\n",
    "\n",
    "            total_messages = len(messages_info)\n",
    "            if total_messages > threshold:\n",
    "                extracted_dialog = await extract_message_info(messages_info)\n",
    "                filtered_dialogs = pd.concat([filtered_dialogs, pd.DataFrame(extracted_dialog, columns=[\"Message\", \"Sender\", \"Date\"])])\n",
    "                if verbose: \n",
    "                    total += 1\n",
    "                    run_time = time.time() - start_time\n",
    "                    print(f\"Dialogs processed: {total}, left: {len(dialogs) - total}. Run time: {run_time:.2f} seconds\") \n",
    "        return filtered_dialogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **If you have >10k messages, it will take a long time to run. Hope you are patient.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 1e+03 ns, total: 2 µs\n",
      "Wall time: 5.25 µs\n",
      "Connecting with <telethon.sessions.sqlite.SQLiteSession object at 0x11056a580>\n",
      "Total dialogs: 161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3_/rlcbd6q14f36221lk26svch40000gn/T/ipykernel_16101/956007910.py:44: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  filtered_dialogs = pd.concat([filtered_dialogs, pd.DataFrame(extracted_dialog, columns=[\"Message\", \"Sender\", \"Date\"])])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogs processed: 1, left: 160. Run time: 4.98 seconds\n",
      "Dialogs processed: 2, left: 159. Run time: 17.58 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Server closed the connection: [Errno 54] Connection reset by peer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FloodWaitError: sleeping for 114 seconds.\n",
      "FloodWaitError: sleeping for 114 seconds.\n",
      "Dialogs processed: 3, left: 158. Run time: 1344.39 seconds\n",
      "FloodWaitError: sleeping for 117 seconds.\n",
      "FloodWaitError: sleeping for 116 seconds.\n",
      "FloodWaitError: sleeping for 111 seconds.\n",
      "FloodWaitError: sleeping for 108 seconds.\n",
      "FloodWaitError: sleeping for 113 seconds.\n",
      "FloodWaitError: sleeping for 105 seconds.\n",
      "FloodWaitError: sleeping for 112 seconds.\n",
      "FloodWaitError: sleeping for 110 seconds.\n",
      "Dialogs processed: 4, left: 157. Run time: 2750.08 seconds\n",
      "FloodWaitError: sleeping for 99 seconds.\n",
      "Dialogs processed: 5, left: 156. Run time: 274.20 seconds\n",
      "FloodWaitError: sleeping for 98 seconds.\n",
      "Dialogs processed: 6, left: 155. Run time: 217.82 seconds\n",
      "FloodWaitError: sleeping for 62 seconds.\n",
      "FloodWaitError: sleeping for 113 seconds.\n",
      "Dialogs processed: 7, left: 154. Run time: 746.40 seconds\n",
      "Dialogs processed: 8, left: 153. Run time: 12.89 seconds\n",
      "FloodWaitError: sleeping for 81 seconds.\n",
      "Dialogs processed: 9, left: 152. Run time: 249.51 seconds\n",
      "FloodWaitError: sleeping for 109 seconds.\n",
      "Dialogs processed: 10, left: 151. Run time: 181.47 seconds\n",
      "Dialogs processed: 11, left: 150. Run time: 24.32 seconds\n",
      "Dialogs processed: 12, left: 149. Run time: 5.39 seconds\n",
      "Dialogs processed: 13, left: 148. Run time: 55.98 seconds\n",
      "Dialogs processed: 14, left: 147. Run time: 61.07 seconds\n",
      "Dialogs processed: 15, left: 146. Run time: 5.57 seconds\n",
      "Dialogs processed: 16, left: 145. Run time: 14.00 seconds\n",
      "FloodWaitError: sleeping for 63 seconds.\n",
      "FloodWaitError: sleeping for 111 seconds.\n",
      "Dialogs processed: 17, left: 144. Run time: 588.54 seconds\n",
      "FloodWaitError: sleeping for 103 seconds.\n",
      "Dialogs processed: 18, left: 143. Run time: 201.38 seconds\n",
      "Dialogs processed: 19, left: 142. Run time: 3.11 seconds\n",
      "Dialogs processed: 20, left: 141. Run time: 13.10 seconds\n",
      "Dialogs processed: 21, left: 140. Run time: 75.71 seconds\n",
      "FloodWaitError: sleeping for 106 seconds.\n",
      "Dialogs processed: 22, left: 139. Run time: 127.06 seconds\n",
      "Dialogs processed: 23, left: 138. Run time: 9.76 seconds\n",
      "Dialogs processed: 24, left: 137. Run time: 18.04 seconds\n",
      "Dialogs processed: 25, left: 136. Run time: 20.33 seconds\n",
      "Dialogs processed: 26, left: 135. Run time: 47.16 seconds\n",
      "Dialogs processed: 27, left: 134. Run time: 12.56 seconds\n",
      "Dialogs processed: 28, left: 133. Run time: 6.56 seconds\n",
      "Dialogs processed: 29, left: 132. Run time: 5.80 seconds\n",
      "FloodWaitError: sleeping for 85 seconds.\n",
      "Dialogs processed: 30, left: 131. Run time: 196.56 seconds\n",
      "Dialogs processed: 31, left: 130. Run time: 5.15 seconds\n",
      "Dialogs processed: 32, left: 129. Run time: 11.17 seconds\n",
      "Dialogs processed: 33, left: 128. Run time: 47.27 seconds\n",
      "Dialogs processed: 34, left: 127. Run time: 85.75 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3_/rlcbd6q14f36221lk26svch40000gn/T/ipykernel_16101/956007910.py:44: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  filtered_dialogs = pd.concat([filtered_dialogs, pd.DataFrame(extracted_dialog, columns=[\"Message\", \"Sender\", \"Date\"])])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogs processed: 35, left: 126. Run time: 11.89 seconds\n",
      "Dialogs processed: 36, left: 125. Run time: 7.65 seconds\n",
      "Dialogs processed: 37, left: 124. Run time: 6.64 seconds\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "async def main():\n",
    "    if os.path.exists(f\"parsers\\{session_name}.session-journal\"):\n",
    "        print(f\"Session {session_name} exists. Please delete it and restart the script. Or change the session name in the script.\")\n",
    "        sys.exit()\n",
    "    else:\n",
    "        await client.start(phone_number)\n",
    "        print(f\"Connecting with {client.session}\")\n",
    "        data = await parse_data(message_limit=None, dialogs_limit=None, verbose=1)\n",
    "        data = pd.DataFrame(data, columns=[\"Message\", \"Sender\", \"Date\"])\n",
    "        data[\"Sent_by_me\"] = int(my_telegram_id) == data[\"Sender\"]\n",
    "        return data\n",
    "        client.disconnect()\n",
    "        print(\"DONE\")\n",
    "\n",
    "data = await main()\n",
    "#client.disconnect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to_csv(r'full_telegram_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message       0\n",
       "Sender        0\n",
       "Date          0\n",
       "Sent_by_me    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are there NAN values?\n",
    "data.isna().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
